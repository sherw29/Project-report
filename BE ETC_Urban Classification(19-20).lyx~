#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\begin_modules
customHeadersFooters
fixltx2e
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "ae" "default"
\font_sans "lmss" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family sfdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 4cm
\rightmargin 2cm
\bottommargin 4cm
\headheight 2cm
\headsep 2cm
\footskip 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\size large
DEVELOPMENT OF AN EFFECTIVE CLASSIFICATION TECHNIQUE TO CLASSIFY SETTLEMENTS
 INTO VARIOUS LAND COVER FEATURES
\end_layout

\begin_layout Standard
\align center

\series bold
\size large
Project Report
\end_layout

\begin_layout Standard
\align center

\shape slanted
Submitted in partial fulfillment of the requirements for the
\end_layout

\begin_layout Standard
\align center

\shape slanted
Bachelors Degree in Engineering
\end_layout

\begin_layout Standard
\align center
by
\end_layout

\begin_layout Standard
\align center

\series bold
\size large
Sherwin Colaco 
\family roman
\series default
(Reg No:1613006)
\end_layout

\begin_layout Standard
\align center

\series bold
\size large
Shivam Bale 
\family roman
\series default
(Reg No:1613003)
\end_layout

\begin_layout Standard
\align center

\series bold
\size large
Keith Pinto 
\family roman
\series default
(Reg No:1613023)
\end_layout

\begin_layout Standard
\align center

\shape slanted
Under the guidance of
\end_layout

\begin_layout Standard
\align center

\series bold
\size large
Dr.Varsha Turkar
\end_layout

\begin_layout Standard
\align center
Head of Department
\end_layout

\begin_layout Standard
\align center
Department of E&TC,DBCE
\end_layout

\begin_layout Standard
\align center
&
\end_layout

\begin_layout Standard
\align center

\series bold
\size large
Dr.Shreyas Simu
\end_layout

\begin_layout Standard
\align center
Assistant Professor
\end_layout

\begin_layout Standard
\align center
Department of E&TC,DBCE
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size large
ACKNOWLEDGEMENT
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
It is not possible to complete a project without the assistance and encouragemen
t of other people.
 In our efforts towards the realization of project work, we have drawn the
 guidance of many people and we would like to express our heartfelt gratitude
 to all people who helped in fulfilling the accomplishment of this project.
 We would like to express our profound gratitude to Our Director, Rev.
 Fr.
 Kinley D’Cruz for providing us the necessary infrastructure to carry out
 our project work easily.
 We are highly indebted to our principal, Dr.
 Neena Panandikar for allowing us to take up this project.
 We would like to express our deep gratitude to Dr.
 Varsha Turkar, Head of Department of Electronics and Telecommunication
 Engineering and our internal project guide and Dr.Shreyas Simu project co-guide
 for their exemplary guidance, monitoring, unconditional support and constant
 encouragement throughout that has made our project successful.
 We also would like to thank them for sparing time and providing necessary
 information patiently and for their co-operation in preparation of this
 report.
 Their constant motivation and inspiration have led to the successful completion
 of our project targets so far.
 We would also like to thank all the faculty members of Don Bosco College
 of Engineering for their critical advice and guidance during various phases
 of our project.
 We also extend our gratitude to ETC Lab Assistants, Technical staff and
 Librarian for assisting us in bring together the project and providing
 resources whenever required by us for our project work.
 Lastly, we place on records, a deep sense of thankfulness to Almighty,
 our family and friends for their blessings, inspiration and constant support
 from the time we ventured into this project till now and those who have
 helped us directly and indirectly for the accomplishment of the project.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Center Header

\end_layout

\begin_layout Left Header

\size scriptsize
Development of an Effective Classification Technique to Classify Settlements
 into Various Land Cover Features
\end_layout

\begin_layout Right Header

\end_layout

\begin_layout Center Footer

\end_layout

\begin_layout Left Footer

\size footnotesize
Department of Electronics and Telecommunication Engineering
\end_layout

\begin_layout Right Footer
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
thepage
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Abstract
\noindent
Although India is one of the less urbanized countries of the world with
 only 27.78% of the population living in urban agglomerations, the country
 is facing a serious crisis of Urban growth at the present time.
 Urbanization has been an instrument of economic, social and political progress
 but it has also led to serious socio-economic problems.
 The sheer magnitude of urban population, haphazard and unplanned growth
 of urban areas and a desperate lack of infrastructure are the main causes
 of such a situation.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Abstract
\noindent
Effective Urban Planning is a simple but powerful solution in order to ensure
 that such problems do not persist in the years to follow or are at least
 reduced to an acceptable minimum.
 Settlement planning requires hours of deep analytic study on existing settlemen
t information as well as information on surrounding areas in a particular
 region.
 In order to obtain this information, officials will need to survey large
 amounts of data with a minimum amount of on-field work.
\begin_inset VSpace defskip
\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Abstract
\noindent
Remote sensing uses satellites to capture images and can survey large areas
 at a time in a matter of seconds which would normally take months of manual
 surveying for a field professional.
 Since satellite image datasets are readily available on the internet today
 for all regions, the use of remote sensing provides the best possible approach
 which satisfies a majority of the objective criteria required for urban
 classification.
\begin_inset VSpace defskip
\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Abstract
\noindent
In this project we aim to develop an effective classification technique
 to classify microwave images and categorize the identified settlements
 into various landcover features such as slums, residential areas, open
 spaces, forest, lakes, etc.
 which will help in the urban planning process.
\end_layout

\begin_layout Abstract
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
INTRODUCTION
\end_layout

\begin_layout Standard
\noindent
Remote sensing is the process of acquiring information about the earth’s
 surface without coming in contact with it.
 This is done by emitting energy and recording the reflected energy back
 which is further processed and analyzed to obtain information.
 Remote sensing is further subdivided into two categories
\end_layout

\begin_layout Enumerate
Active Remote sensing: The antenna itself emits radiation that is then received
 to form an image at the receiver.
\end_layout

\begin_layout Enumerate
Passive Remote sensing: Such systems make use of the energy radiated by
 the sun for imaging purposes they do not emit radiation of their own and
 hence depend on the sun's energy for their functioning.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/my files/Sem 7/MWE/problems/saa.PNG

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Active & Passive Remote Sensing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(
\shape italic
\size scriptsize
source
\shape default
:https://staff.aub.edu.lb/~webeco/rs%20lectures.htm
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Subsection
MICROWAVE REMOTE SENSING
\end_layout

\begin_layout Standard
Microwave Sensing includes active as well as passive forms of remote sensing
 systems that measure the energy that is naturally existing i.e.
 sunlight are called passive remote sensors, they can only be used to detect
 energy when energy is naturally occurring.
 Active sensors, on the other hand, illuminate the required object using
 an independent energy source.
 Radiation is emitted by the active sensor which then falls on the target
 that is under investigation and the reflected radiation is measured by
 the sensor.
 The advantage of using active sensors is that the measurements can be obtained
 anytime regardless of the time of day or season.
 Microwaves have a longer wavelength compared to Visible and infrared waves
 in the electromagnetic spectrum thus microwaves have special properties
 that are important for remote sensing.
 Longer wavelength microwave radiations can penetrate through cloud cover,
 haze, dust, and the heaviest rainfall as microwave wavelengths are not
 susceptible to atmospheric scattering which is the main problem when dealing
 with shorter optical wavelengths.
 Thus, microwave energy can be detected under almost all weather and environment
al conditions so that informative data can be collected at any time.
 The microwave region of the spectrum is initially quite large as compared
 to visible and infrared and there are several wavelength ranges or bands
 that microwaves are commonly divided into
\end_layout

\begin_layout Standard
• Ka, K and Ku band: very early airborne radar systems but uncommon today.
\end_layout

\begin_layout Standard
• X- Band: Used extensively on airborne systems for military purposes and
 terrain mapping
\end_layout

\begin_layout Standard
• C- Band: Commonly used in airborne research systems
\end_layout

\begin_layout Standard
• S-Band: used onboard the Russian ALMAZ satellite
\end_layout

\begin_layout Standard
• P-Band: contains the longest wavelength and is used on NASA experimental
 airborne research systems
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/my files/Sem 7/MWE/problems/band.PNG

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Microwave Frequency Bands
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(
\shape italic
\size scriptsize
source
\shape default
: https://www.pgc.umn.edu/guides/commercial-imagery/intro-satellite-imagery/
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Subsection
SYNTHETIC APERTURE RADAR (SAR)
\end_layout

\begin_layout Standard
SAR also known as Synthetic Aperture Radar is the method of achieving a
 uniform, fine azimuth resolution across the entire image swath.
 The use of SAR for remote sensing is particularly suited for tropical countries.
 Since SAR is an active sensor, which provides its own source of illumination,
 it can, therefore, operate day or night; able to illuminate with variable
 look angle and can select wide area coverage.
 In addition, the topography change can be derived from the phase difference
 between measurement using radar interferometry.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/my files/Sem 7/MWE/problems/sar.PNG

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Synthetic Aperature Radar
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(
\shape italic
\size scriptsize
source
\shape default
:https://crisp.nus.edu.sg/~research/tutorial/mw.htm
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Subsection
POLARIMETRIC SAR
\end_layout

\begin_layout Standard
\noindent
Polarimetric SAR or PolSAR systems enhance the capabilities of any basic
 radar systems by allowing the sensors to transmit and receive in multiple
 polarizations, by utilizing different polarizations we can identify unique
 and distinct features of the target.
 Some features that can be observed in one polarization cannot be observed
 in another polarization.
 A target's characteristic is defined more clearly by combining all polarization
 modes.
 In basic terms, a radar system can transmit and receive either a Horizontal
 (H) Or a Vertical (V) polarization of a radio wave.
 Polarimetric SAR can be performed by either transmitting horizontal or
 vertical polarizations or by receiving horizontal or vertical polarization,
 or both.
\end_layout

\begin_layout Standard
\noindent
There can be 4 combinations of transmitting and receiving polarizations
 :
\end_layout

\begin_layout Standard
\noindent
• HH: - For horizontal transmit and horizontal receive.
\end_layout

\begin_layout Standard
\noindent
• VV: - For vertical transmit and vertical receive.
\end_layout

\begin_layout Standard
\noindent
• HV: - For horizontal transmit and vertical receive.
\end_layout

\begin_layout Standard
\noindent
• VH: - For vertical transmit and horizontal receive.
\end_layout

\begin_layout Standard
\noindent
The first two polarization (HH & VV) combinations are referred to as “like
 polarized”.
 The last two polarization (HV & VH) combinations are referred to as “cross-pola
rized”.
\end_layout

\begin_layout Standard
\noindent
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Subsection
RADAR IMAGING SATELLITES
\end_layout

\begin_layout Standard
\noindent
Radar is developed to detect the presence of a target and to find the distance
 of a target from the radar by using radio waves.
\end_layout

\begin_layout Standard
\noindent
Radar transmits short bursts or pulses of microwave signals in the direction
 of the object and records the strength of the received signal along with
 the time requires to return it back.
 Radar antennas are attached to aircrafts known as Airborne radars or satellites
 known as spaceborne radars in order to produce images of earth known as
 an imaging radar.
\end_layout

\begin_layout Standard
\noindent
The look angle and the swath coverage are affected by altitude variations
 of the radar.
 Some operational spaceborne SAR systems are mentioned below
\end_layout

\begin_layout Itemize
ENVISAT-1 launched in March 2002 and uses frequencies lying in the C-band
 of microwaves for imaging
\end_layout

\begin_layout Itemize
RADARSAT-2 launched in December 2007 uses frequencies lying in the C-band
 of microwaves for imaging
\end_layout

\begin_layout Itemize
ALOS-1 launched in January 2006 uses frequencies lying in the L-band of
 microwaves for imaging
\end_layout

\begin_layout Itemize
ALOS-2 will continue the L-band SAR observations of the ALOS PALSAR (Phased
 Array L-band Synthetic Aperture Radar) and will expand data utilization
 by enhancing its performance.
\end_layout

\begin_layout Itemize
TerraSAR-X launched in June 2007 uses frequencies lying in the X-band of
 microwaves for imaging
\end_layout

\begin_layout Itemize
RISAT-1 launched in April 2012 uses frequencies lying in the C-band of microwave
s for imaging
\end_layout

\begin_layout Itemize
UAVSAR- (Unmanned Aerial Vehicle Synthetic Aperture Radar) uses frequencies
 lying in the L-band of microwaves for imaging
\end_layout

\begin_layout Itemize
AIRSAR-(Airborne Synthetic Aperture RADAR)uses frequencies lying in the
 L-band C-band as well as P-band of microwaves for imaging
\end_layout

\begin_layout Standard
An AIRSAR dataset of the San Francisco Bay region was used for this project
 since datasets of this sensor are freely available over the internet.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
LITERATURE REVIEW
\end_layout

\begin_layout Standard
Urban classification like the land-cover and land-use classification is
 one of the most important applications of PolSAR.
 Many algorithms have been developed for supervised and unsupervised Urban
 classification.
 In supervised classification, training sets for each class are selected,
 based on ground truth.
 For each pixel, the PolSAR gives information in three real and three complex
 parameters.
 When ground truth maps are not available, it makes the selection of training
 sets difficult.
 Unsupervised classification classifies the image automatically by funding
 clusters based on a certain criterion (similarity and dissimilarity).
 However, the final class recognition is done manually.
 PolSAR images are affected by noise called speckle.
 Noise appears in PolSAR images due to the coherent interference of waves
 reflected from many elementary scatters.
 Speckle in PolSAR images affects the image interpretation and reduces the
 classification accuracy.
 To avoid this various speckle filters can be used.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
The fundamental concepts of Microwave Remote Sensing explains how images
 are acquired from satellites and various satellites that are used in the
 process.
 The various properties of the microwaves and its applications are covered
 in [2].
 Pre-processing techniques, image enhancement, transformation and classification
 of digital images are also explained in brief.
\begin_inset VSpace defskip
\end_inset


\begin_inset Newline linebreak
\end_inset


\end_layout

\begin_layout Standard
\noindent
[2] proposes the use of Random Forests as classiﬁcation method for building
 detection,which is able to deal with a broad variety of different features
 and are designed to include contextual knowledge as well.
 Random Forests can be designed to exploit contextual knowledge, and therefore
 surpass pixel-based classiﬁcation methods.
 Random Forests grow several trees, each of them considered as weak classiﬁer,
 and combine their output to obtain a classiﬁer, whose performance is more
 accurate and robust than that of every single tree alone.
 During the training of each tree, the training image is divided into several
 overlapping, randomly distributed patches.
 Therefore, each training sample has a dimensionality of S×S×F, where S
 is the patch size and F the number of used features.
 Each internal node projects this high-dimensional data point p to a single
 dimension by the usage of a speciﬁc projection function.
 All the parameters of the projection including the type of projection are
 chosen randomly.
 Only one feature is involved in one projection.
 The local context of a pixel is used.
 It is assumed, that objects of the same class should consist of similar
 structures, which will lead to similar projections.
 Images are structured data and contain context information.
 This kind of information was ﬁrstly exploited by the usage of speciﬁc features
 like texture, which are based on spatial neighbourhoods.
 Secondly, it was used during the induction of each tree, since each projection
 is based on the local neighbourhood of a pixel.
 Class estimation of a speciﬁc pixel often contains useful information about
 the probable class estimations of its neighbours.
 Therefore, in each leaf node n not only the probability for the patche's
 central pixel is stored, but the spatial probability distribution of the
 whole patch.
 Since the layover effect causes the image of high buildings to merge with
 those of surrounding buildings, not all image areas of single buildings
 are clearly distinguishable.
 However, if there is enough distance then single buildings are clearly
 identiﬁable.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
The researchers in [4] proposed a method, where Genetic Algorithm (GAs)
 and Support Vector Machines (SVMs) or Multi-Layer Perceptron neural networks
 were used on the decomposed results that maximized classification accuracy.
 The averaged classification accuracy of the proposed method reached up
 to 95%.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
[7] processed polarimetric SAR data from ALOS PALSAR, ENVISAT ASAR and SIR-C
 for classification of wet and arid lands .Their results from Mumbai data
 show that ALOS HH & HV data is better than ASAR HH&VV for the classification
 of wet lands.
 Using SIR-C fully polarimetric data water logged areas including ponds
 and lakes identified.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
Multi-frequency and multi-polarized data can be classified using MDC, MLC,
 ANN, SVM and DTC as mention in [8].
 The researchers explained how classification accuracy increases after combining
 different polarizations of SIR-C L- and C-band.
 It was found that the classification accuracy further improves after applying
 Enhanced Lee Filter.
 Similarly, RADARSAT-2 C-band, ALOS PALSAR L-band and TerraSAR X-band data
 over Mumbai were classified individually and in combination.
 The land cover classification capabilities of fully versus partially and
 hybrid polarimetric SAR data for L- and C-band were studied.
 An effective technique for classification of urban areas which are not
 orthogonal to the radar Line of Sight is by using polarization orientation
 compensation (POC) and Circular Correlation Coefficient (CCC).
 The proposed method increases the classification accuracy by 40%.
\end_layout

\begin_layout Standard
\noindent
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
[11] proposed a technique to find indices of polarimetric correlation coefficien
t in linear and circular polarization bases to extract useful features from
 polarimetric SAR data.
 These indices were selected by the applicability of the polarimetric analysis
 based on the polarimetric scattering model and the property of azimuthal
 symmetry.
 This technique was applied to Pi-SAR/X-SAR data.
 This technique shows its capability to discriminate between vegetation
 area and the urban area.
\end_layout

\begin_layout Standard
\noindent
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
[4] proposed a novel on semi-supervised Dimensionality Reduction(DR) algorithm
 SNC for PolSAR feature extraction and terrain classification.
 The content explains how a low-dimensional subspace is learned from the
 original high-dimensional feature space of PolSAR data by a designed objective
 function.
 The spatial groups are constructed from the adjacent pixels in the image
 domain and used as the basic unit during DR, which weakens the influences
 of the speckle noise.
 Classification accuracies on a variety of PolSAR data obtained prove that
 the separability of the data is greatly enhanced with the SNC algorithm
 The SNC performs well not only on the homogeneous terrains but also the
 heterogeneous terrains such as urban from different PolSAR systems.
 The only drawback of the proposed algorithm is that the algorithm has difficult
y in distinguishing pixels on the boundaries of classes.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
[9] attempts to assign one such physical scattering model to the real part
 of T23 (Re{T23}) and develop a new scattering power decomposition model,
 called as the seven component scattering decomposition (7SD).
 The physical scattering model for Re{T23} is derived from a particular
 configuration of dipoles (referred to as “mixed dipole” configuration),
 which gives rise to compound scattering.
 In earlier models the problem pertaining to Re{T23} was not realized because
 the [T ] matrix was compensated for the orientation of the target about
 the radar line of sight (LoS) .
 This compensation reduced Re{T23} to zero.
 The seven components that were described by G.Singh are Ps, Pd , Pv , Ph,
 Pod, Pcd, and Pmd.
 [T ]s, [T ]d , [T ]v , [T ]h, [T ]od, [T ]cd, and [T ]md are the scattering
 submatrices that were acquired by surface scattering, double-bounce scattering,
 volume scattering, helix scattering, oriented dipole scattering, compound
 dipole scattering (oriented quarter-wave reflectors scattering), and mixed
 dipole scattering, respectively.
 The highlight of this model was that it worked on the original coherency
 matrix without any transformation.The compound scattering derived from the
 mixed dipole configuration finds its application in identifying man-made
 structures and species of vegetation where the branches have the mixed
 dipole or combination of dihedral configurations.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
This paper [8] attempts to assign one such physical scattering model to
 the real part of T23 (Re{T23}) and develop a new scattering power decomposition
 model, called as the sevencomponent scattering decomposition (7SD).
\end_layout

\begin_layout Standard
\noindent
The 7 components that are obtained are as follows.
\end_layout

\begin_layout Standard
\noindent
Ps, Pd , Pv , Ph, Pod, Pcd, and Pmd are the scattering powers to be determined.
 [T ]s, [T ]d , [T ]v , [T ]h, [T ]od, [T ]cd, and [T ]md are the scattering
 submatrices that are acquired by surface scattering, double-bounce scattering,
 volume scattering, helix scattering, oriented dipole scattering, compound
 dipole scattering (oriented quarter-wave reflectors scattering), and mixed
 dipole scattering, respectively.The highlight of the new proposed model
 is that it works on the original coherency matrix without any transformation.Sin
ce the model accounts for Re{T23}, it retains Re{T23}.
 The compound scattering derived from the mixed dipole configuration finds
 its application in identifying man-made structures and species of vegetation
 where the branches have the mixed dipole or combination of dihedral configurati
ons.
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
\noindent
RESEARCH GAP
\end_layout

\begin_layout Standard
The previous work in this field includes the use of microwave radar satellite
 images for a wide range of applications.
 These include classification of images based on various landforms such
 as water, settlements and forests.
 Classification has also been used to categorize regions depending on vegetation
 characteristics which have been used to identify and differentiate between
 various crop species.
 Previous applications, however, do not include the use of satellite image
 classification to distinguish between various land cover features.
 The proposed system will classify satellite images based on various land
 cover features such as slums, towns, cities etc.
 These images can be used by government officials to facilitate effective
 urban planning.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
OBJECTIVES
\end_layout

\begin_layout Standard
The main objective of this project is to create a system that will classify
 satellite images of the selected region in order to provide government
 officials with sufficient information on settlements in the area in order
 to aid them in urban planning process.
\end_layout

\begin_layout Standard
\noindent
The design process of such a system will include the following steps
\end_layout

\begin_layout Enumerate
Classify the settlement using conventional (existing) filters using various
 windows sizes.
\end_layout

\begin_layout Enumerate
Classify the settlements using decomposed images.
\end_layout

\begin_layout Enumerate
Classify the settlement using coherency or covariance matrix,
\end_layout

\begin_layout Enumerate
Compare the results of step (2) and step (3)
\end_layout

\begin_layout Enumerate
Select the method with best results of the two for the urban classifier.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
METHODOLOGY
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/my files/Sem 7/MWE/problems/Block diagram.JPG

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
methodology
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
PolSAR DATA
\end_layout

\begin_layout Standard
Various datatsets are available online.These datasets span over different
 frequency bands such as L-band C-band,and P-band, etc.Each band provides
 varying depths of information of the same ROI due to their varying wavelengths.T
he focus of this project is to use satellite images within the L-band frequency
 range to classify various land cover features.For our requirements sample
 datasets were collected from different sources over the internet.The city
 of San Francisco (AirSAR dataset) was selected for this purpose.
\end_layout

\begin_layout Subsection
SPECKLE REMOVAL
\end_layout

\begin_layout Standard
Speckle noise is a granular interference that inherently exists in and degrades
 the quality of the active synthetic aperture radar (SAR) image.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/EMISAR-L-band-PolSAR-image-from-Foulum-in-Denmark-Five-homogeneous-areas-are-selected-to.png
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
PolSAR image affected with speckle noise
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(
\shape italic
\size scriptsize
source
\shape default
:www.researchgate.net%2Ffigure%2FEMISAR-L-band-PolSAR-image-from-Foulum-in-Denmark
-Five-homogeneous
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Subsection
DECOMPOSTION OF IMAGES
\end_layout

\begin_layout Standard
\noindent
Polarimetric Synthetic Aperture Radar (PolSAR) is sensitive to the geometric
 structure, orientation and physical characteristics of scattering targets.
 Polarimetric Target Decomposition (PTD) is a useful tool to identify and
 separate scattering mechanisms.The objective of Target decomposition (TD)
 theory is to express the average scattering mechanism as the sum of independent
 elements to associate a physical mechanism with each component.
 There are two types of TD.
 One is Coherent (CTD) and other is Incoherent (ICTD).
\end_layout

\begin_layout Subsubsection*

\size large
Coherent Decomposition
\end_layout

\begin_layout Standard
CTD was developed to characterize completely polarized scattered waves for
 which fully polarimetric information is contained in the scattering matrix.
 The CTD can be used only to study coherent targets also known as point
 or pure targets.
 Manmade objects are the example of pure targets.
 Pauli, Krogager, Cameron are Coherent type of decomposition.
\end_layout

\begin_layout Subsubsection*

\size large
In-coherent Decomposition
\end_layout

\begin_layout Standard
\noindent
ICTD was developed to characterize distributed scatterers.
 Freeman, Van Zyl and Yamaguchi are different types of ICTD.
 Freeman and Van Zyl has three types of scattering mechanisms namely volume,
 double bounce and surface or single bounce.
 Yamaguchi 4- component has one additional scattering mechanism that is
 helix.
 Helix scattering often appears in complex urban areas where as disappears
 in almost all natural distributed scenarios.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
One of the most used PTD methods is the three-component decomposition method,
 which decomposes PolSAR data into three categories: surface or single-bounce,
 double-bounce, and volume-bounce.This approach is best when either double
 bounce contribution or surface contribution is close to zero.
 In real cases, especially in double-bounce and single-bounce contribution,
 speckle will be introduced due to artificial settings(issues related to
 the satellite).
 Another problem of the three-component decomposition method is that the
 volume scattering power is usually overestimated in oriented urban areas.
 Therefore [7] added a fourth helix component to their decomposition to
 account for the disadvantages of the 3 component decomposition.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
Polarimetric decomposition approaches provide a measure of the relative
 contributions of backscatter from different scattering mechanisms and hence,
 the selection of proper decomposition methods plays a vital role in the
 classification of natural distributed targets.Over the years a number of
 newer decomposition models have been introduced by scientsits like Gulab
 Singh [ref no.] that are more efficient and provide more information on
 scattering components.
\end_layout

\begin_layout Standard
\noindent
Different Models of Decomposition that were proposed:
\end_layout

\begin_layout Itemize
\noindent
FDD [6]: The pioneering work of all model-based scattering power decomposition,
 the FDD fits three simple scattering mechanisms to explain the dominant
 scattering mechanisms of surface, double-bounce, and volume, assuming the
 condition of reflection symmetry for naturally occurring targets.
\end_layout

\begin_layout Itemize
\noindent
Yamaguchi Four-Component Original (Y4O) [7]: For targets that do not obey
 the reflection symmetry condition, the Y4O model explains the helix scattering.
\end_layout

\begin_layout Itemize
\noindent
Four-Component Scattering Power Decomposition With Extended Volume Scattering
 Model (S4R) : In an attempt to improve FDD and Y4O a disorientation, or
 desying operation is performed on [T ] using the rotation matrix [R(θ )].
 This rotation operation reduces the number of independent parameters of
 [T ] from nine to eight, thus increasing the percentage of information
 extracted in Y4R [12].
 Similar to the Y4R model, S4R incorporates the rotation of the coherency
 matrix, making Re{T23} = 0 and minimizing the depolarized term from T33.
 However, it discriminates volume scattering coming from the vegetation
 and oriented-dihedral structures by implementing the extended volume scattering
 model for dihedral to improve the discrimination of oriented-urban areas
 from vegetation.
 There still exists the issue of identifying scattering from structures
 in highly oriented urban areas that cannot be solved by S4R model alone.
 The solution to this problem is addressed in the latest six-component scatterin
g power decomposition that accounts for two new scattering mechanisms.
\end_layout

\begin_layout Itemize
\noindent
Six-Component Scattering Matrix Power Decomposition (6SD) : 6SD model addresses
 the above-mentioned problem by introducing two new physical scattering
 models of oriented-dipoles (od) and compound-dipole (cd) structures for
 Re{T13} and Im{T13} elements, respectively.
 Details of the submatrices along with the implementation of the six-component
 scattering powers from the rotated coherency matrix are given in .
\end_layout

\begin_layout Itemize
\noindent
Six-Component Scattering Matrix Power Decomposition (6SD) : Ps, Pd , Pv
 , Ph, Pod, Pcd, and Pmd are the scattering powers to be determined.
 [T ]s, [T ]d , [T ]v , [T ]h, [T ]od, [T ]cd, and [T ]md are the scattering
 submatrices that are acquired by surface scattering, double-bounce scattering,
 volume scattering, helix scattering, oriented dipole scattering, compound
 dipole scattering (oriented quarter-wave reflectors scattering), and mixed
 dipole scattering, respectively.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
For the purpose of this project the following decompositions models were
 used for classification purposes and their results were compaired to check
 classification efficiency.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/my files/Sem 7/MWE/problems/159-FigureA.1-1.png

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Back Scattering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center

\size scriptsize
(
\shape italic
source
\shape default
:https://www.semanticscholar.org/paper/Polarimetric-Synthetic-Aperture-Radar-
\end_layout

\begin_layout Plain Layout
\align center

\size scriptsize
(SAR)-for-and-Choe/82fc573e489453cca60f502818edc5d2e0ae5296
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Subsection
CLASSIFICATION
\end_layout

\begin_layout Standard
\noindent
Classification is the task of assigning a set of given data elements to
 a given set of labels or classes such that the cost of assigning the data
 element to a class is minimum.
 Classification of polarimetric SAR images has become a very important topic
 after the availability of Polarimetric SAR images through ENVISAT ASAR,
 ALOS PALSAR, SIR-C and Radarsat2.
\end_layout

\begin_layout Standard
\noindent
Urban classification involves classifying decomposed images into various
 land cover features such as slums, residential areas, open spaces, forest,
 lakes, etc.
\end_layout

\begin_layout Standard
\noindent
This can be achived using two broad categories of classifiers:
\end_layout

\begin_layout Subsubsection*
PARAMETRIC CLASSIFIERS
\end_layout

\begin_layout Standard
Parametric classifiers make use of algorithms that simplify the function
 to a known form and are called parametric machine learning algorithms.
\end_layout

\begin_layout Standard
\noindent
It proposes a learning model that summarizes data with a set of parameters
 of fixed size (independent of the number of training examples).
 parametric classifiers have fixed number of parameters irrespective of
 the amount of data to be classified.
\end_layout

\begin_layout Standard
\noindent
Some more examples of parametric machine learning algorithms include:
\end_layout

\begin_layout Itemize
Logistic Regression
\end_layout

\begin_layout Itemize
Linear Discriminant Analysis
\end_layout

\begin_layout Itemize
Perceptron
\end_layout

\begin_layout Itemize
Naive Bayes
\end_layout

\begin_layout Itemize
Simple Neural Networks
\end_layout

\begin_layout Standard
Benefits of Parametric Machine Learning Algorithms:
\end_layout

\begin_layout Itemize
Simpler: These methods are easier to understand and interpret results.
\end_layout

\begin_layout Itemize
Speed: Parametric models are very fast to learn from data.
\end_layout

\begin_layout Itemize
Less Data: They do not require as much training data and can work well even
 if the fit to the data is not perfect.
\end_layout

\begin_layout Subsubsection*
NON-PARAMETRIC CLASSIFIERS
\end_layout

\begin_layout Standard
\noindent
Algorithms that do not make strong assumptions about the form of the mapping
 function are called nonparametric machine learning algorithms.
 Nonparametric methods are used when there is a lot of data and no prior
 knowledge of the desired outcome is available.
\end_layout

\begin_layout Standard
\noindent
Some more examples of popular nonparametric machine learning algorithms
 are:
\end_layout

\begin_layout Itemize
k-Nearest Neighbors
\end_layout

\begin_layout Itemize
Decision Trees like CART C4.5
\end_layout

\begin_layout Itemize
Support Vector Machines
\end_layout

\begin_layout Standard
Benefits of Nonparametric Machine Learning Algorithms:
\end_layout

\begin_layout Itemize
Flexibility: Capable of fitting a large number of functional forms.
\end_layout

\begin_layout Itemize
Power: No assumptions (or weak assumptions) about the underlying function.
\end_layout

\begin_layout Itemize
Performance: Can result in higher performance models for prediction.
\end_layout

\begin_layout Subsubsection*
ARTIFICIAL NEURAL NETWORKS
\end_layout

\begin_layout Standard
Artificial Neural Networks or ANN is an information processing paradigm
 that is inspired by the way the biological nervous system such as brain
 processes information.
 It is composed of large number of highly interconnected processing elements
 called neurons that work in unison to solve a specific problem.
 Learning in a neural network is closely related to how we learn in our
 regular lives and activities.
 Neural networks require a trainer in order to describe what should have
 been produced as a response to a given input.
 Based on the difference between the actual value and the predicted value,
 an error value is computed and sent back to the system.
 For each layer of the network, the error value is analyzed and used to
 adjust the threshold and weights for the next input.
 The main aim is to minimize the error.
 The lower the error value, the closer the actual value to the predicted
 value.
 In this way, the error keeps becoming marginally lesser in each run as
 the network learns how to analyze values.
 In order to simulate a neural network in MATLAB for the purpose of this
 project, an inbuilt function newff was used.
 newff in MATLAB creates a feedforward backpropagation network by taking
 training samples and expected results from the user.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/awdawd.png
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Artificial Neural Network Layout
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(
\shape italic
\size scriptsize
source
\shape default
:https://www.researchgate.net/figure/Feedforward-backpropagation-neural-network-to
pology_fig4_266201206
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Subsubsection*
RANDOM FOREST
\end_layout

\begin_layout Standard
Random forest, like its name implies, consists of a large number of individual
 decision trees that operate as a group.
 Each tree in the forest is formed by taking different unique features or
 combinations of features of training samples at random and creating levels
 of decision nodes to form trees.
 Due to the randomness of the training sample selection process a number
 of trees can be obtained.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/awdawdawd.png
	scale 75

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Random forest generated model
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(
\shape italic
\size scriptsize
source
\shape default
:https://www.mathworks.com/help/stats/random-forest.html
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
Each individual tree in the random forest spits out a class prediction and
 the class with the most votes becomes the Random Forest model’s prediction.
 Hence it can be summarized that the random forest classifier consists of
 a combination of tree classifiers where each classifier is generated using
 a random vector sampled independently from the input vector, and each tree
 casts a unit vote for the most popular class to classify an input vector.
 For the purpose of this project which was simulated in MATLAB, The Treebagger
 function was used.
 Treebagger is an inbuilt function available in MATLAB which in default
 mode simulates the Breiman’s Random forest model also known as Breiman’s
 Bagging model.
 The predict function, another inbuilt function available in MATLAB was
 then used to classify test samples by running them through the generated
 RF model that was obtained in the previous process.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Subsubsection*
DECISION TREES
\end_layout

\begin_layout Standard
A decision tree is a decision support tool that uses a tree-like graph or
 model of decisions and their possible consequences.
 Decision trees also referred to as classification trees and regression
 trees is a predictive model that maps from observations about an item.
 To predict a response, The data is continuously split according to a certain
 parameter.
 The tree can be explained by two entities, namely decision nodes and leaves.
 The leaves are the decisions or final outcomes.
 And the decision nodes are where the data is split.
 Classification trees give responses that are nominal, such as 'true' or
 'false'.
 Regression trees give numeric responses.
 Each step in a prediction involves checking the value of one predictor.
 For example, here is a simple classification tree:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/adawdawdawd.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Binary decision tree
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(
\shape italic
\size scriptsize
source
\shape default
:https://www.mathworks.com/help/stats/decision-trees.html
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
This tree predicts classifications based on two predictors, x1 and x2.
 To predict, start at the top node, represented by a triangle (Δ).
 The first decision is whether x1 is smaller than 0.5.
 If so, follow the left branch, and see that the tree classifies the data
 as type 0.
 If, however, x1 exceeds 0.5, then follow the right branch to the lower-right
 triangle node.
 Here the tree asks if x2 is smaller than 0.5.
 If so, then follow the left branch to see that the tree classifies the
 data as type 0.
 If not, then follow the right branch to see that the tree classifies the
 data as type 1.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
DATASET
\end_layout

\begin_layout Standard
The focus of this project is to use satellite images within the L-band frequency
 range to classify various land cover features.For our requirements sample
 datasets were collected from different sources over the internet.The city
 of San Francisco was selected for this purpose since AIRSAR datasets for
 this city were freely available.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\noindent
San Francisco is extremely dense; it is a very well-planned city with very
 minimal area available for expansion.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/my files/Sem 7/MWE/problems/Capturesan.PNG

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
San Francisco
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(
\shape italic
\size scriptsize
Source
\shape default
:https://www.google.com/intl/en_in/earth/
\size default
)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Subsection*
PAULI RBG IMAGES
\end_layout

\begin_layout Standard
Fig.9 shows the Pauli RGB image obtained.The image represents single bounce
 double bounce and volume bounce information using different colours.Single
 bounce is represented with blue colour,double bounce is represented using
 red and volume bounce information is represented using green.This image
 can then be used to further classify the image.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/my files/Sem 7/MWE/problems/PauliRGB.bmp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Pauli RGB Image
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
RESULTS
\end_layout

\begin_layout Standard
POLSAR PRO V.4.2 was used to implement image processing , three component
 and four component decomposition and was also used to classify the available
 AirSAR dataset in order to study how an image classifier works.
 Image processing techniques were applied on the images.
 Pauli RGB image was obtained by sampling available dataset, out of the
 various filters available Lee Filter was applied to the image to filter
 out noise component.
\end_layout

\begin_layout Standard
\noindent
After studying how a classifier works a MATLAB code was later developed
 to use ANN, decision tree and Random forest classifiers on the existing
 dataset to classify the image.
\end_layout

\begin_layout Subsection
TRAINING DATA
\end_layout

\begin_layout Standard
During execution of the MATLAB code the user was prompted to select training
 areas with the pauli RGB image acting as a reference.
 Data from areas selected by the user in the corresponding three component,
 seven component and four component datasets were extracted and 3 different
 training datasets each containing three component, four component and seven
 component data respectively were obtained.The obtained datasets were then
 used to create nine different models to classifiy the image.These include
 3 decision tree models, 3 random forest models and 3 Artificial neural
 network models for three component, four component and seven component
 data respectively.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/seven_data.PNG
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
seven component training data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/yama_4data.PNG
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Four Component training data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/yama_3 data.PNG
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Three component training data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Subsection
CLASSIFIED IMAGES
\end_layout

\begin_layout Standard
The obtained models were then used to classify the entire sampled image.
\end_layout

\begin_layout Itemize
Image pixels of class:settlement were assingned red colour.
\end_layout

\begin_layout Itemize
Image pixels of class:vegetation were assogned green colour.
\end_layout

\begin_layout Itemize
Image pixels of class:water were assingned blue colour.
\end_layout

\begin_layout Standard
The final images obtained from the code are as shown below.
\end_layout

\begin_layout Subsubsection*
USING DECISION TREE CLASSIFIER
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/decisiontreeThree.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Decision tree classifier image:using three component data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/decisiontreeFour.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Decision tree classifier image:using four component data
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/decisiontreeSeven.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Decision tree classifier image:using seven component data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
USING RANDOM FOREST CLASSIFIER
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/RforestThree.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Random Forest classifier image:using three component data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/RforestFour.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Random Forest classifier image:using four component data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/RforestSeven.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Random Forest classifier image:using seven component data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
USING ARTIFICIAL NEURAL NETWORK CLASSIFIER
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/neuralThree.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
ANN classifier image:using three component data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/neuralFour.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
ANN classifier image:using four component data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename C:/Users/Sherwin Colaco/Pictures/Classified Images/neuralSeven.jpg
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
ANN classifier image:using seven component data
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
CONFUSION MATRIX
\end_layout

\begin_layout Standard
A confusion matrix is a table that is often used to describe the performance
 of a classification model (or “classifier”) on a set of test data for which
 the true values are known.
\end_layout

\begin_layout Itemize
It allows the visualization of the performance of an algorithm.
\end_layout

\begin_layout Itemize
It allows easy identification of confusion between classes e.g.
 one class is commonly mis-labeled as the other.
\end_layout

\begin_layout Itemize
The number of correct and incorrect predictions are summarized with count
 values and broken down by each class.
\end_layout

\begin_layout Standard
The confusion matrix obtained after classification for the above sample
 is as follows
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/my files/Sem 7/MWE/problems/matrix.PNG

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Confusion Matrix
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
98.13% of the training samples of class vegetation were correctly classified
 ,1.64% was reclassified as water and the rest was reclassified as settlements.
\end_layout

\begin_layout Itemize
76.53% of the training samples of class water were correctly classified ,
 8.33% was reclassified as vegetation and the rest was reclassified as settlement
s.
\end_layout

\begin_layout Itemize
47.99% of the training samples of class settlement were correctly classified
 , 1.34% was reclassified as vegetation and the rest was reclassified as
 water.
\end_layout

\begin_layout Subsubsection
DEFINITION OF TERMS
\end_layout

\begin_layout Itemize
Positive (P) : Observation is positive (for example is an apple).
\end_layout

\begin_layout Itemize
Negative (N) : Observation is not positive (for example is not an apple).
\end_layout

\begin_layout Itemize
True Positive (TP) : Observation is positive and is predicted to be positive.
\end_layout

\begin_layout Itemize
False Negative (FN) : Observation is positive but is predicted negative.
\end_layout

\begin_layout Itemize
True Negative (TN) : Observation is negative and is predicted to be negative.
\end_layout

\begin_layout Itemize
False Positive (FP) : Observation is negative but is predicted positive.
\end_layout

\begin_layout Subsubsection
PARAMETERS CALCULATED
\end_layout

\begin_layout Standard
\noindent
Additional Required data(obtained from confusion matrix) :
\end_layout

\begin_layout Enumerate
\noindent
C1 17711 (number of samples taken from class Settlements)
\end_layout

\begin_layout Enumerate
\noindent
C2 10325 (number of samples taken from class Water)
\end_layout

\begin_layout Enumerate
\noindent
C3 18520 (number of samples taken from class Vegetation)
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
The following terms are calculated by making use of the data available.
\end_layout

\begin_layout Itemize
Producers Accuracy:It is the number of reference sites classified accurately
 divided by the total number of reference sites for that class.
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $ProdAcc=(correctlyClassified)/(totalSites)$
\end_inset


\end_layout

\begin_layout Itemize
Users Accuracy:The User's Accuracy is calculated by taking the total number
 of correct classifications for a particular class and dividing it by the
 row total.
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $UsersAcc=(No.ofClass)/(RowTotal)$
\end_inset


\end_layout

\begin_layout Itemize
Error-Rate:- Error rate (ERR) is calculated as the number of all incorrect
 predictions divided by the total number of the dataset.
 The best error rate is 0.0, whereas the worst is 1.0.
\end_layout

\begin_layout Itemize
Total Accuracy:-Accuracy (ACC) is calculated as the number of all correct
 predictions divided by the total number of the dataset.
 The best accuracy is 1.0, whereas the worst is 0.0.
 It can also be calculated by 1 – ERR.
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $TotalAcc=(TP+TN)/(TP+TN+FP+FN)$
\end_inset


\end_layout

\begin_layout Itemize
Random Accuracy:-Random Accuracy is defined as the sum of the products of
 reference likelihood and result likelihood for each class.
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $RandAcc=((ActFalse*PredFalse)+(ActTrue*PredTrue))/total*total$
\end_inset


\end_layout

\begin_layout Itemize
Sensitivity:-Sensitivity (SN) is calculated as the number of correct positive
 predictions divided by the total number of positives.
 It is also called recall (REC) or true positive rate (TPR).
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $Sensitivity(Recall)=TP/(TP+FN)$
\end_inset


\end_layout

\begin_layout Itemize
Specificity(True negative Rate):-Specificity (SP) is calculated as the number
 of correct negative predictions divided by the total number of negatives.
 It is also called true negative rate (TNR).
\end_layout

\begin_layout Itemize
Precision(Positive Predictive value):-Precision (PREC) is calculated as
 the number of correct positive predictions divided by the total number
 of positive predictions.
 It is also called positive predictive value (PPV).
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $Precision=TP/(TP+FP)$
\end_inset


\end_layout

\begin_layout Itemize
False Positive Rate:-False positive rate (FPR) is calculated as the number
 of incorrect positive predictions divided by the total number of negatives.
 The best false positive rate is 0.0 whereas the worst is 1.0.
\end_layout

\begin_layout Itemize
Kappa Statistic:-The Kappa Coefficient is generated from a statistical test
 to evaluate the accuracy of a classification.
 Kappa essentially evaluates how well the classification is performed as
 compared to just randomly assigning values, i.e.
 it checks if the classification did better than the random assignment.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
kappa=(TotalAcc-RandomAcc)/(1-RandomAcc)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
COST ANALYSIS
\end_layout

\begin_layout Standard
For the purpose of obtaining a rough estimate of the project cost the basic
 Constructive Cost Model (CoCoMo) was used.
 The project was categorized as an Organic project.
\end_layout

\begin_layout Standard
\noindent
In order to obtain the final cost the present attribute values at the time
 of writing this report were taken of the internet.The formulae coefficients
 corresponding to the project mode selected were assumed.
\end_layout

\begin_layout Subsubsection
CHARACTERISTIC CALCULATIONS
\end_layout

\begin_layout Subsubsection*
\noindent
Effort
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Effort=A*(KLOC)^{B}pm=0.896*(1.33)^{1.05}=1.20879pm
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Development Time
\end_layout

\begin_layout Subsubsection*
\begin_inset Formula 
\[
Tdev=C*(Effort)^{D}Months=2.5*(1.2088)^{0.38}=2.68679months
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Professionals Required
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Effort/Tdev=1.2088/2.686=0.450
\]

\end_inset


\end_layout

\begin_layout Subsubsection
COST ESTIMATION
\end_layout

\begin_layout Subsubsection*
Technical work cost
\end_layout

\begin_layout Standard
\noindent
Average computer programmer salary per month = ₹ 40,713
\end_layout

\begin_layout Standard
\noindent
Time taken to develop the product = 2.7 months
\end_layout

\begin_layout Standard
\noindent
Cost of hiring a programmer to develop the product = ₹ 1,09,925
\end_layout

\begin_layout Subsubsection*
Cost of Hardware purchased
\end_layout

\begin_layout Standard
HP OMEN 870-244 Desktop Computer: ₹ 1,12,482
\end_layout

\begin_layout Subsubsection*
Cost of Software purchased
\end_layout

\begin_layout Standard
MATLAB licence cost : ₹ 11250
\end_layout

\begin_layout Subsubsection*
Office space
\end_layout

\begin_layout Standard
cost of 3 months at a coworking space: ₹ 30000
\end_layout

\begin_layout Subsubsection*
Other
\end_layout

\begin_layout Standard
Miscellaneous expenses: ₹ 10000
\end_layout

\begin_layout Subsubsection*
Total Cost
\end_layout

\begin_layout Standard
Total Cost was estimated up to: ₹ 
\series bold
2,73,657
\end_layout

\begin_layout Standard
\noindent
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
CONCLUSION
\end_layout

\begin_layout Standard
In order to classify the dataset into different classes nine different classific
ation models were used
\end_layout

\begin_layout Itemize
The first model used a binary tree classifier which was trained using a
 3 component dataset shown in [fig:14]
\end_layout

\begin_layout Itemize
The second model used a binary tree classifier which was trained using a
 4 component dataset shown in [fig:13]
\end_layout

\begin_layout Itemize
The third model used a binary tree classifier which was trained using a
 7 component dataset shown in [fig:12]
\end_layout

\begin_layout Itemize
The fourth model used an Artificial Neural Network classifier which was
 trained using a 3 component dataset shown in [fig:14]
\end_layout

\begin_layout Itemize
The fifth model used an Artificial Neural Network classifier which was trained
 using a 4 component dataset shown in [fig:13]
\end_layout

\begin_layout Itemize
The sixth model used an Artificial Neural Network classifier which was trained
 using a 7 component dataset shown in [fig:12]
\end_layout

\begin_layout Itemize
The seventh model used a Random Forest classifier which was trained using
 a 3 component dataset shown in [fig:14]
\end_layout

\begin_layout Itemize
The eight model used a Random Forest classifier which was trained using
 a 4 component dataset shown in [fig:13]
\end_layout

\begin_layout Itemize
The ninth model used a Random Forest classifier which was trained using
 a 7 component dataset shown in [fig:12]
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
taking the results into consideration the following could be concluded:
\end_layout

\begin_layout Itemize
\noindent
Of the three datasets used in the project Gulab Singh's seven component
 dataset was found to be the best since it provided the most accurate results
\end_layout

\begin_layout Itemize
Out of the three classifier models used the Random forest classifier was
 found to provide the most accurate results when compaired to the binary
 tree classifier and ANN classifier
\end_layout

\begin_layout Itemize
A combination of the Random Forest classifier trained using the seven component
 dataset [fig:12] was found to provide the most accurate and acceptable
 result shown in [Fig:20]
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
BIBLIOGRAPHY
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "C:/Users/Sherwin Colaco/Documents/fff"
options "plain"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\end_body
\end_document
